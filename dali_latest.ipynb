{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8144c603-7c2c-4aae-85d0-dac4237b842e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d6d4c92-6ef0-4c7d-9760-c7fd6014fe5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch Baseline Epoch 1/5: 100%|██████████| 1184/1184 [02:33<00:00,  7.71it/s, loss=1.96]\n",
      "PyTorch Baseline Epoch 2/5: 100%|██████████| 1184/1184 [02:01<00:00,  9.75it/s, loss=1.64]\n",
      "PyTorch Baseline Epoch 3/5: 100%|██████████| 1184/1184 [02:22<00:00,  8.33it/s, loss=1.18] \n",
      "PyTorch Baseline Epoch 4/5: 100%|██████████| 1184/1184 [02:30<00:00,  7.86it/s, loss=1.4]  \n",
      "PyTorch Baseline Epoch 5/5: 100%|██████████| 1184/1184 [02:32<00:00,  7.78it/s, loss=0.955]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing DALI file list to ./data/food-101/train.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/nvidia/dali/ops/__init__.py:269: DeprecationWarning: The argument `output_dtype` is a deprecated alias for `dtype`. Use `dtype` instead.\n",
      "  kwargs = _handle_arg_deprecations(schema, kwargs, operator_name)\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/nvidia/dali/ops/__init__.py:269: DeprecationWarning: The argument `image_type` is no longer used and will be removed in a future release.\n",
      "  kwargs = _handle_arg_deprecations(schema, kwargs, operator_name)\n",
      "DALI Baseline Epoch 1/5: 100%|██████████| 1184/1184 [01:59<00:00,  9.91it/s, loss=1.27]\n",
      "DALI Baseline Epoch 2/5: 100%|██████████| 1184/1184 [01:59<00:00,  9.92it/s, loss=1.03] \n",
      "DALI Baseline Epoch 3/5: 100%|██████████| 1184/1184 [01:59<00:00,  9.93it/s, loss=1.03] \n",
      "DALI Baseline Epoch 4/5: 100%|██████████| 1184/1184 [01:59<00:00,  9.91it/s, loss=0.446]\n",
      "DALI Baseline Epoch 5/5: 100%|██████████| 1184/1184 [01:59<00:00,  9.91it/s, loss=0.654]\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/nvidia/dali/ops/__init__.py:269: DeprecationWarning: The argument `output_dtype` is a deprecated alias for `dtype`. Use `dtype` instead.\n",
      "  kwargs = _handle_arg_deprecations(schema, kwargs, operator_name)\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/nvidia/dali/ops/__init__.py:269: DeprecationWarning: The argument `image_type` is no longer used and will be removed in a future release.\n",
      "  kwargs = _handle_arg_deprecations(schema, kwargs, operator_name)\n",
      "DALI +  AMP Epoch 1/5:   0%|          | 0/1184 [00:00<?, ?it/s]/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "DALI +  AMP Epoch 1/5: 100%|██████████| 1184/1184 [01:01<00:00, 19.29it/s, loss=1.33]\n",
      "DALI +  AMP Epoch 2/5: 100%|██████████| 1184/1184 [01:00<00:00, 19.52it/s, loss=1.05] \n",
      "DALI +  AMP Epoch 3/5: 100%|██████████| 1184/1184 [01:00<00:00, 19.57it/s, loss=1.15] \n",
      "DALI +  AMP Epoch 4/5: 100%|██████████| 1184/1184 [01:00<00:00, 19.63it/s, loss=0.424]\n",
      "DALI +  AMP Epoch 5/5: 100%|██████████| 1184/1184 [01:00<00:00, 19.56it/s, loss=0.632]\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/nvidia/dali/ops/__init__.py:269: DeprecationWarning: The argument `output_dtype` is a deprecated alias for `dtype`. Use `dtype` instead.\n",
      "  kwargs = _handle_arg_deprecations(schema, kwargs, operator_name)\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/nvidia/dali/ops/__init__.py:269: DeprecationWarning: The argument `image_type` is no longer used and will be removed in a future release.\n",
      "  kwargs = _handle_arg_deprecations(schema, kwargs, operator_name)\n",
      "DALI +  AMP + Compile Epoch 1/5: 100%|██████████| 1184/1184 [02:32<00:00,  7.77it/s, loss=1.29]\n",
      "DALI +  AMP + Compile Epoch 2/5: 100%|██████████| 1184/1184 [00:57<00:00, 20.74it/s, loss=1.09] \n",
      "DALI +  AMP + Compile Epoch 3/5: 100%|██████████| 1184/1184 [00:57<00:00, 20.71it/s, loss=1.12] \n",
      "DALI +  AMP + Compile Epoch 4/5: 100%|██████████| 1184/1184 [00:57<00:00, 20.59it/s, loss=0.446]\n",
      "DALI +  AMP + Compile Epoch 5/5: 100%|██████████| 1184/1184 [00:57<00:00, 20.47it/s, loss=0.61] \n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:124: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import Food101\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# NVIDIA DALI imports \n",
    "try:\n",
    "    from nvidia.dali.pipeline import Pipeline\n",
    "    import nvidia.dali.ops as ops\n",
    "    import nvidia.dali.types as types\n",
    "    from nvidia.dali.plugin.pytorch import DALIClassificationIterator, LastBatchPolicy\n",
    "except ImportError:\n",
    "    print(\"=\"*80)\n",
    "    print(\"!!! NVIDIA DALI not installed; skipping DALI parts. !!!\")\n",
    "    print(\"=\"*80)\n",
    "    DALIClassificationIterator = None\n",
    "\n",
    "# Configuration -\n",
    "BATCH_SIZE   = 64\n",
    "MAX_EPOCHS   = 5\n",
    "NUM_CLASSES  = 101\n",
    "DATA_DIR     = \"./data\"\n",
    "DEVICE       = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Disable DALI on CPU\n",
    "if DEVICE == \"cpu\":\n",
    "    print(\"Warning: Running on CPU; DALI will be disabled.\")\n",
    "    DALIClassificationIterator = None\n",
    "\n",
    "# Download Food-101 if needed\n",
    "def download_food101(root_dir):\n",
    "    marker = os.path.join(root_dir, \"food-101\")\n",
    "    if os.path.isdir(marker):\n",
    "        return\n",
    "    print(\"Downloading Food-101...\")\n",
    "    Food101(root=root_dir, split='train', download=True)\n",
    "    Food101(root=root_dir, split='test',  download=True)\n",
    "\n",
    "# Create DALI file list of ABSOLUTE paths \n",
    "def create_dali_file_list(root_dir, output_file=\"train.txt\"):\n",
    "    ds = Food101(root=root_dir, split='train', download=False)\n",
    "    out_path = os.path.join(root_dir, \"food-101\", output_file)\n",
    "    print(\"Writing DALI file list to\", out_path)\n",
    "    with open(out_path, 'w') as f:\n",
    "        for img_path, label in zip(ds._image_files, ds._labels):\n",
    "            f.write(f\"{os.path.abspath(img_path)} {label}\\n\")\n",
    "    return out_path\n",
    "\n",
    "# PyTorch DataLoader \n",
    "def get_pytorch_dataloader(root_dir, batch_size, split='train'):\n",
    "    is_train = (split=='train')\n",
    "    transforms_list = []\n",
    "    if is_train:\n",
    "        transforms_list += [\n",
    "            transforms.Resize(256),\n",
    "            transforms.RandomResizedCrop(224),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "        ]\n",
    "    else:\n",
    "        transforms_list += [\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "        ]\n",
    "    transforms_list += [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
    "    ]\n",
    "    ds = Food101(root=root_dir, split=split, transform=transforms.Compose(transforms_list), download=False)\n",
    "    return DataLoader(ds, batch_size=batch_size, shuffle=is_train,\n",
    "                      num_workers=(4 if DEVICE=='cuda' else 0), pin_memory=(DEVICE=='cuda'))\n",
    "\n",
    "# dALI DataLoader (with resizing\n",
    "if DALIClassificationIterator:\n",
    "    class DaliTrainPipeline(Pipeline):\n",
    "        def __init__(self, batch_size, num_threads, device_id, file_list_path):\n",
    "            super().__init__(batch_size, num_threads, device_id, seed=12)\n",
    "            self.input  = ops.readers.File(file_root=\"\", file_list=file_list_path,\n",
    "                                           random_shuffle=True, name=\"Reader\")\n",
    "            self.decode = ops.decoders.Image(device=\"mixed\")\n",
    "            self.resize = ops.Resize(device=\"gpu\", resize_shorter=256)\n",
    "            self.cmn    = ops.CropMirrorNormalize(\n",
    "                device=\"gpu\", output_dtype=types.FLOAT, output_layout=types.NCHW,\n",
    "                crop=(224,224), mean=[0.485*255,0.456*255,0.406*255],\n",
    "                std=[0.229*255,0.224*255,0.225*255], image_type=types.RGB)\n",
    "            self.coin = ops.random.CoinFlip(probability=0.5)\n",
    "\n",
    "        def define_graph(self):\n",
    "            rng = self.coin()\n",
    "            jpegs, labels = self.input()\n",
    "            images = self.decode(jpegs).gpu()\n",
    "            images = self.resize(images)\n",
    "            out    = self.cmn(images, mirror=rng)\n",
    "            return out, labels.gpu()\n",
    "\n",
    "    def get_dali_dataloader(data_dir, batch_size):\n",
    "        file_list = os.path.join(data_dir, \"food-101\", \"train.txt\")\n",
    "        pipeline = DaliTrainPipeline(batch_size=batch_size, num_threads=4,\n",
    "                                     device_id=0, file_list_path=file_list)\n",
    "        return DALIClassificationIterator(\n",
    "            pipelines=[pipeline], last_batch_policy=LastBatchPolicy.PARTIAL,\n",
    "            reader_name=\"Reader\")\n",
    "\n",
    "# Model & Evaluatio\n",
    "def get_model():\n",
    "    model = torchvision.models.resnet50(weights='IMAGENET1K_V1')\n",
    "    model.fc = nn.Linear(model.fc.in_features, NUM_CLASSES)\n",
    "    return model.to(DEVICE)\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            preds = model(inputs).argmax(dim=1)\n",
    "            correct += preds.eq(labels).sum().item()\n",
    "            total   += labels.size(0)\n",
    "    return correct / total\n",
    "\n",
    "# Training Loop with Robust Batch Detection \n",
    "from torch.cuda.amp import GradScaler\n",
    "\n",
    "def train(model, loader, optimizer, criterion, num_epochs,\n",
    "          desc, grad_accum_steps=1, use_amp=False):\n",
    "    scaler = GradScaler() if use_amp else None\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        loop = tqdm(loader, desc=f\"{desc} Epoch {epoch+1}/{num_epochs}\")\n",
    "        for step, batch in enumerate(loop):\n",
    "            # Detect DALI batch by element type\n",
    "            if isinstance(batch, (list, tuple)) and len(batch) and isinstance(batch[0], dict):\n",
    "                data_dict = batch[0]\n",
    "                inputs = data_dict['data']\n",
    "                labels = data_dict['label'].squeeze(-1).long()\n",
    "            else:\n",
    "                inputs, labels = batch\n",
    "                inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            if use_amp:\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    loss = criterion(model(inputs), labels) / grad_accum_steps\n",
    "                scaler.scale(loss).backward()\n",
    "            else:\n",
    "                loss = criterion(model(inputs), labels) / grad_accum_steps\n",
    "                loss.backward()\n",
    "\n",
    "            if (step + 1) % grad_accum_steps == 0:\n",
    "                if use_amp:\n",
    "                    scaler.step(optimizer)\n",
    "                    scaler.update()\n",
    "                else:\n",
    "                    optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            loop.set_postfix(loss=(loss.item() * grad_accum_steps))\n",
    "\n",
    "        # Reset DALI iterator if in use\n",
    "        if isinstance(loader, DALIClassificationIterator):\n",
    "            loader.reset()\n",
    "\n",
    "    return time.time() - start_time\n",
    "\n",
    "# Main Execution & 5-Experiment series\n",
    "if __name__ == \"__main__\":\n",
    "    download_food101(DATA_DIR)\n",
    "    test_loader = get_pytorch_dataloader(DATA_DIR, BATCH_SIZE, split='test')\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    results = []\n",
    "\n",
    "    # 1) PyTorch Baseline\n",
    "    pt_model = get_model()\n",
    "    pt_loader= get_pytorch_dataloader(DATA_DIR, BATCH_SIZE, split='train')\n",
    "    pt_opt   = optim.SGD(pt_model.parameters(), lr=1e-3, momentum=0.9)\n",
    "    if DEVICE=='cuda': torch.cuda.reset_peak_memory_stats()\n",
    "    t1 = train(pt_model, pt_loader, pt_opt, criterion, MAX_EPOCHS,\n",
    "               \"PyTorch Baseline\", grad_accum_steps=1, use_amp=False)\n",
    "    a1 = evaluate(pt_model, test_loader)\n",
    "    m1 = torch.cuda.max_memory_allocated()/1e6 if DEVICE=='cuda' else None\n",
    "    results.append((\"PyTorch Baseline\", t1, a1, m1))\n",
    "\n",
    "    if DALIClassificationIterator:\n",
    "        create_dali_file_list(DATA_DIR)\n",
    "\n",
    "        # 2) DALI Baseline\n",
    "        db_model = get_model()\n",
    "        db_loader= get_dali_dataloader(DATA_DIR, BATCH_SIZE)\n",
    "        db_opt   = optim.SGD(db_model.parameters(), lr=1e-3, momentum=0.9)\n",
    "        if DEVICE=='cuda': torch.cuda.reset_peak_memory_stats()\n",
    "        t2 = train(db_model, db_loader, db_opt, criterion, MAX_EPOCHS,\n",
    "                   \"DALI Baseline\", grad_accum_steps=1, use_amp=False)\n",
    "        a2 = evaluate(db_model, test_loader)\n",
    "        m2 = torch.cuda.max_memory_allocated()/1e6 if DEVICE=='cuda' else None\n",
    "        results.append((\"DALI Baseline\", t2, a2, m2))\n",
    "\n",
    "\n",
    "        # 4) DALI +AMP\n",
    "        daa_model= get_model()\n",
    "        daa_loader= get_dali_dataloader(DATA_DIR, BATCH_SIZE)\n",
    "        daa_opt   = optim.SGD(daa_model.parameters(), lr=1e-3, momentum=0.9)\n",
    "        if DEVICE=='cuda': torch.cuda.reset_peak_memory_stats()\n",
    "        t4 = train(daa_model, daa_loader, daa_opt, criterion, MAX_EPOCHS,\n",
    "                   \"DALI +  AMP\", grad_accum_steps=1, use_amp=True)\n",
    "        a4 = evaluate(daa_model, test_loader)\n",
    "        m4 = torch.cuda.max_memory_allocated()/1e6 if DEVICE=='cuda' else None\n",
    "        results.append((\"DALI +  AMP\", t4, a4, m4))\n",
    "\n",
    "        # 5) DALI +  AMP + Compile\n",
    "        dac_model= get_model()\n",
    "        dac_loader= get_dali_dataloader(DATA_DIR, BATCH_SIZE)\n",
    "        dac_opt   = optim.SGD(dac_model.parameters(), lr=1e-3, momentum=0.9)\n",
    "        if DEVICE=='cuda': torch.cuda.reset_peak_memory_stats()\n",
    "        dac_model= torch.compile(dac_model)\n",
    "        t5 = train(dac_model, dac_loader, dac_opt, criterion, MAX_EPOCHS,\n",
    "                   \"DALI +  AMP + Compile\", grad_accum_steps=1, use_amp=True)\n",
    "        a5 = evaluate(dac_model, test_loader)\n",
    "        m5 = torch.cuda.max_memory_allocated()/1e6 if DEVICE=='cuda' else None\n",
    "        results.append((\"DALI +  AMP + Compile\", t5, a5, m5))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e81c469-420e-4a7a-a786-9eb5ed232fbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0acf542-7803-4384-9381-c7813c5ac79f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      " Experiment                       Time(s)   Accuracy(%)   Peak GPU Mem(MB)\n",
      "============================================================\n",
      "PyTorch Baseline                  720.2        80.28            6251.2\n",
      "DALI Baseline                     597.0        81.12            6445.0\n",
      "DALI +  AMP                       303.4        81.24            4056.0\n",
      "DALI +  AMP + Compile             382.0        81.16            4342.4\n",
      "============================================================\n",
      "\n",
      "Speedup (PyTorch / DALI Baseline): 1.21×\n"
     ]
    }
   ],
   "source": [
    "# Summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\" Experiment                       Time(s)   Accuracy(%)   Peak GPU Mem(MB)\")\n",
    "print(\"=\"*60)\n",
    "for name, t, acc, mem in results:\n",
    "    mem_str = f\"{mem:.1f}\" if mem is not None else \"N/A\"\n",
    "    print(f\"{name:30s} {t:8.1f}   {acc*100:10.2f}   {mem_str:>15s}\")\n",
    "print(\"=\"*60)\n",
    "if len(results) >= 2:\n",
    "    speedup = results[0][1]/results[1][1]\n",
    "    print(f\"\\nSpeedup (PyTorch / DALI Baseline): {speedup:.2f}×\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac86f94-b847-4abf-9364-4ba801fd869a",
   "metadata": {},
   "source": [
    "### 1:30 min from torch.compile should subtracted from the comparison , because of one time graph creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f02e5b-b3e1-44da-97e4-2ffe2a7167f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
